You are an expert AI pair programmer helping me build a clean, local, Python-based web application called “Chart AI Assistant”.

The application lets users:
- Upload CSV or Excel files, most commonly containing wide-format time-series data (e.g. economic indicators, monthly/quarterly series, one row per indicator/item, one column per time period)
- Inspect, lightly edit, and store data in a local SQLite database
- Build and customize charts by selecting items/indicators, time ranges, aggregations, and visual styles via GUI
- Ask natural-language questions about a single dataset; an LLM (via AWS Bedrock) interprets the request, generates safe SQL, proposes chart configurations, and provides narrative summaries

Strict constraints:
- Local-only execution (runs on my PC, no cloud deployment)
- Backend: Python 3.11+, FastAPI, SQLite only
- Frontend: React SPA
- Charting library: Apache ECharts via echarts-for-react (npm install echarts echarts-for-react)
- Dependencies managed via requirements.txt (backend) and package.json (frontend)
- LLM: AWS Bedrock (model chosen via config; I will handle credentials)
- No heavy external services, no multi-user features, no authentication

Preferred folder structure:

backend/
├── main.py                 # FastAPI app entry point
├── api/                    # routers
│   ├── datasets.py
│   ├── charts.py
│   └── llm.py
├── models/                 # Pydantic schemas + optional SQLAlchemy models
├── services/               # business logic
│   ├── dataset_service.py
│   ├── chart_service.py
│   └── llm_service.py
├── db/                     # database setup, session, DDL utils
├── config.py               # paths, DB URL, Bedrock model ID, etc.
└── storage/                # file upload & path handling

Core SQLite schema (optimized for wide-format time-series + hierarchy):

1. datasets
   - id                INTEGER PRIMARY KEY AUTOINCREMENT
   - name              TEXT NOT NULL
   - original_filename TEXT NOT NULL
   - stored_file_path  TEXT NOT NULL
   - created_at        TEXT NOT NULL     (ISO 8601)
   - updated_at        TEXT
   - row_count         INTEGER
   - column_count      INTEGER

2. items                     -- one row per data series / indicator / line item
   - id                INTEGER PRIMARY KEY AUTOINCREMENT
   - dataset_id        INTEGER NOT NULL
   - line              INTEGER               -- original line number from file (if present)
   - name              TEXT NOT NULL         -- indicator name (e.g. "Personal consumption expenditures")
   - parent_id         INTEGER               -- self-referential FK to items.id (NULL = top level)
   - level             INTEGER DEFAULT 0     -- hierarchy depth (0 = top, 1 = sub, etc.)
   - code              TEXT                  -- optional extracted code (e.g. "(55)")
   - is_measure        BOOLEAN DEFAULT 1     -- whether this is a numeric series suitable for charting
   - description       TEXT                  -- optional user note or description
   - FOREIGN KEY (dataset_id) REFERENCES datasets(id) ON DELETE CASCADE
   - FOREIGN KEY (parent_id) REFERENCES items(id) ON DELETE SET NULL

3. data_points               -- long-format storage: one row per value
   - id                INTEGER PRIMARY KEY AUTOINCREMENT
   - item_id           INTEGER NOT NULL
   - date              TEXT NOT NULL         -- ISO 8601 date (e.g. '2000-01-01') or period string
   - value             REAL                  -- numeric value
   - created_at        TEXT NOT NULL
   - FOREIGN KEY (item_id) REFERENCES items(id) ON DELETE CASCADE
   -- Indexes
   CREATE INDEX idx_data_points_item_date ON data_points(item_id, date);
   CREATE INDEX idx_data_points_date ON data_points(date);

4. saved_charts
   - id                INTEGER PRIMARY KEY AUTOINCREMENT
   - dataset_id        INTEGER NOT NULL
   - name              TEXT NOT NULL
   - description       TEXT
   - config_json       TEXT NOT NULL         -- ECharts option-compatible JSON
   - created_at        TEXT NOT NULL
   - updated_at        TEXT
   - thumbnail_path    TEXT                   -- optional path to preview PNG
   - FOREIGN KEY (dataset_id) REFERENCES datasets(id) ON DELETE CASCADE

Charting library (frontend):
- Use **Apache ECharts** via **echarts-for-react**
- Render charts using <ReactECharts option={chartOption} />
- Map saved_charts.config_json and user selections to full ECharts 'option' objects
- Support at minimum: line, bar, stacked bar, area, pie, scatter
- Leverage ECharts features: multiple series, dataZoom, toolbox, tooltip, legend, multiple axes, annotations

Main features / screens:

1. Dataset List
   - List datasets (name, filename, created, row count, time range if detected)
   - Upload new CSV/Excel, rename, delete

2. Dataset Detail / Data Table
   - Paginated, editable table view (preferably tree + flat view toggle)
   - Show hierarchy (collapsible tree of items)
   - Inline editing of values
   - Sidebar with item metadata (name, level, parent, description)

3. Chart Builder
   - Select dataset
   - Select one or multiple items (support hierarchy tree picker)
   - Select time range (date picker or from/to periods)
   - Optional: aggregation (sum, avg, etc. if multiple items selected)
   - Select chart type (line, bar, stacked bar, area, pie, scatter initially)
   - Customize: title, colors, legend position, line style, data zoom, toolbox, annotations
   - Live preview using ReactECharts
   - Save chart configuration → saved_charts table (store as ECharts 'option' compatible JSON)

4. Saved Charts
   - List of saved chart configs (name, dataset, thumbnail if available)
   - Load, edit, clone, delete, export (JSON or image)

5. Chat / Insights Panel
   - Natural language input about the current dataset
   - LLM generates:
     - Safe SQL query (SELECT only, single dataset)
     - Suggested ECharts-compatible chart config (if chart-related request)
     - Short narrative summary of results

Ingestion rules (important):
- On upload: detect if file is wide-format time-series (many date-like columns after 1-2 fixed columns)
- Identify fixed columns (e.g. Line, Item, description) vs. time columns (YYYYMmm, YYYY-MM, etc.)
- Parse hierarchy from leading spaces or indentation in name/description column
- Melt wide data → long format → insert into data_points with parsed ISO dates
- Build items table with parent_id / level relationships
- Store original file for reference

LLM & SQL safety rules:
- Only allow: SELECT, WHERE, GROUP BY, ORDER BY, basic aggregates (SUM, AVG, MIN, MAX, COUNT), simple arithmetic
- Forbid: DDL, DML (INSERT/UPDATE/DELETE), PRAGMA, ATTACH, subqueries across datasets, etc.
- Always scope queries to one dataset (WHERE dataset_id = ?)
- Provide LLM with:
  - Table schema
  - Hierarchy tree summary (top-level items + some examples)
  - Sample item names
  - Date range of the dataset
- Validate generated SQL before execution (keyword blocklist + basic parsing)
- Log all generated queries for debugging

Example ECharts option structure (for config_json):

{
  "title": { "text": "PCE Components Over Time" },
  "tooltip": { "trigger": "axis" },
  "legend": { "top": "top" },
  "toolbox": { "feature": { "dataZoom": {}, "saveAsImage": {} } },
  "xAxis": { "type": "time" },
  "yAxis": { "type": "value" },
  "series": [
    {
      "name": "Personal consumption expenditures",
      "type": "line",
      "data": [["2000-01-01", 72.961], ["2000-02-01", 73.191], ...]
    },
    {
      "name": "Durable goods",
      "type": "line",
      "data": [...]
    }
  ],
  "dataZoom": [{ "type": "inside" }]
}

Your role:
- Provide clear, modular, well-commented code snippets
- Suggest incremental steps (backend first → DB → ingestion → API → frontend)
- Explain design decisions
- Focus on readability, error handling, and extensibility
- When working on charting, show how to map data → ECharts option object
- Do not generate an entire codebase at once — ask question and get my direction

Now help me build this application step by step.
